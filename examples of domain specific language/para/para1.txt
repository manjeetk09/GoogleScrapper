A small programming language specifically designed to communicate solutions for a particular domain of problems.
One simple example for Domain Specific Language(DSL) is HTML which is used for the particular domain called web-based applications.
A domain-specific language (DSL) is a computer language specialized to a particular application domain. This is in contrast to a general-purpose language (GPL), which is broadly applicable across domains. There is a wide variety of DSLs, ranging from widely used languages for common domains, such as HTML for web pages, down to languages used by only one or a few pieces of software, such as Emacs Lisp for GNU Emacs and XEmacs. DSLs can be further subdivided by the kind of language, and include domain-specific markup languages, domain-specific modeling languages (more generally, specification languages), and domain-specific programming languages. Special-purpose computer languages have always existed in the computer age, but the term "domain-specific language" has become more popular due to the rise of domain-specific modeling. Simpler DSLs, particularly ones used by a single application, are sometimes informally called mini-languages.
A domain-specific language (DSL) is a computer language specialized to a particular application domain. This is in contrast to a general-purpose language (GPL), which is broadly applicable across domains. There is a wide variety of DSLs, ranging from widely used languages for common domains, such as HTML for web pages, down to languages used by only one or a few pieces of software, such as Emacs Lisp for GNU Emacs and XEmacs. DSLs can be further subdivided by the kind of language, and include domain-specific markup languages, domain-specific modeling languages (more generally, specification languages), and domain-specific programming languages. Special-purpose computer languages have always existed in the computer age, but the term "domain-specific language" has become more popular due to the rise of domain-specific modeling. Simpler DSLs, particularly ones used by a single application, are sometimes informally called mini-languages.
A domain-specific language (DSL) is a computer language specialized to a particular application domain. This is in contrast to a general-purpose language (GPL), which is broadly applicable across domains. There is a wide variety of DSLs, ranging from widely used languages for common domains, such as HTML for web pages, down to languages used by only one or a few pieces of software, such as Emacs Lisp for GNU Emacs and XEmacs. DSLs can be further subdivided by the kind of language, and include domain-specific markup languages, domain-specific modeling languages (more generally, specification languages), and domain-specific programming languages. Special-purpose computer languages have always existed in the computer age, but the term "domain-specific language" has become more popular due to the rise of domain-specific modeling. Simpler DSLs, particularly ones used by a single application, are sometimes informally called mini-languages.
A domain-specific language (DSL) is a computer language specialized to a particular application domain. This is in contrast to a general-purpose language (GPL), which is broadly applicable across domains. There is a wide variety of DSLs, ranging from widely used languages for common domains, such as HTML for web pages, down to languages used by only one or a few pieces of software, such as Emacs Lisp for GNU Emacs and XEmacs. DSLs can be further subdivided by the kind of language, and include domain-specific markup languages, domain-specific modeling languages (more generally, specification languages), and domain-specific programming languages. Special-purpose computer languages have always existed in the computer age, but the term "domain-specific language" has become more popular due to the rise of domain-specific modeling. Simpler DSLs, particularly ones used by a single application, are sometimes informally called mini-languages.
A domain-specific language (DSL) is a computer language specialized to a particular application domain. This is in contrast to a general-purpose language (GPL), which is broadly applicable across domains. There is a wide variety of DSLs, ranging from widely used languages for common domains, such as HTML for web pages, down to languages used by only one or a few pieces of software, such as Emacs Lisp for GNU Emacs and XEmacs. DSLs can be further subdivided by the kind of language, and include domain-specific markup languages, domain-specific modeling languages (more generally, specification languages), and domain-specific programming languages. Special-purpose computer languages have always existed in the computer age, but the term "domain-specific language" has become more popular due to the rise of domain-specific modeling. Simpler DSLs, particularly ones used by a single application, are sometimes informally called mini-languages.
A domain-specific language (DSL) is a computer language specialized to a particular application domain. This is in contrast to a general-purpose language (GPL), which is broadly applicable across domains. There is a wide variety of DSLs, ranging from widely used languages for common domains, such as HTML for web pages, down to languages used by only one or a few pieces of software, such as Emacs Lisp for GNU Emacs and XEmacs. DSLs can be further subdivided by the kind of language, and include domain-specific markup languages, domain-specific modeling languages (more generally, specification languages), and domain-specific programming languages. Special-purpose computer languages have always existed in the computer age, but the term "domain-specific language" has become more popular due to the rise of domain-specific modeling. Simpler DSLs, particularly ones used by a single application, are sometimes informally called mini-languages.


The line between general-purpose languages and domain-specific languages is not always sharp, as a language may have specialized features for a particular domain but be applicable more broadly, or conversely may in principle be capable of broad application but in practice used primarily for a specific domain. For example, Perl was originally developed as a text-processing and glue language, for the same domain as AWK and shell scripts, but was mostly used as a general-purpose programming language later on. By contrast, PostScript is a Turing complete language, and in principle can be used for any task, but in practice is narrowly used as a page description language.
The line between general-purpose languages and domain-specific languages is not always sharp, as a language may have specialized features for a particular domain but be applicable more broadly, or conversely may in principle be capable of broad application but in practice used primarily for a specific domain. For example, Perl was originally developed as a text-processing and glue language, for the same domain as AWK and shell scripts, but was mostly used as a general-purpose programming language later on. By contrast, PostScript is a Turing complete language, and in principle can be used for any task, but in practice is narrowly used as a page description language.
The line between general-purpose languages and domain-specific languages is not always sharp, as a language may have specialized features for a particular domain but be applicable more broadly, or conversely may in principle be capable of broad application but in practice used primarily for a specific domain. For example, Perl was originally developed as a text-processing and glue language, for the same domain as AWK and shell scripts, but was mostly used as a general-purpose programming language later on. By contrast, PostScript is a Turing complete language, and in principle can be used for any task, but in practice is narrowly used as a page description language.
v t e
v t e
v t e
v t e
v t e
v t e


A small programming language specifically designed to communicate solutions for a particular domain of problems.
One simple example for Domain Specific Language(DSL) is HTML which is used for the particular domain called web-based applications.
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
We use domain specific languages to describe tasks related to automating the analysis and transformation of source code: A lexical language to describe language elements (this is common in the compiler field), used to generate fast FSAs for breaking text in such elements. Our is special in handling full Unicode and supporting the conversion of values (e.g., numbers and strings) to native computer binary representations. It also provides a push-down state automation to allow the lexer to handle complex entities such as the contents of regular expressions. (Most lexers for langauges having REs treat the RE as a single language element; it should be clear that REs have very complex content and should be lexed in detail).. a grammar specification (also common in the compiler field) for describing how lexical elements are composable to form valid sentences in the langauge. Ours is backed up (unusually) by a full context-free parsing mechanism, enabling our DSL to specify a parseable version of full C++14.. a box language, used to specify how to build and compose “boxes” (rectangular regions of text), used to define how a prettyprinter converts an abstract syntax tree back into nicely indented/formatted text.. an attribute grammar, which decorates the above grammar specification, to enable the computation of arbitrary analyses over parse trees.. a rule language for specifying code transformations in terms of source code fragments. This is actually pretty unusual in itself. A more recent extension allows the source pattern to be intepreted/matched against the source code in terms of data flows, so it isnt just pure syntactic match.. A parallel programming language in which to write program analysis and transformation tools, combining the above elements. While a lot of the parallel language is rather traditional, the part which specifies parallelism is not, enabling one to specify pure-parallelism, partial-order parallelism, or team based parallelism easily..
Domain Specific Languages (DSLs) have been around since I've been in computing, but it's hard to find much information about how to work with them. DSLs are small languages, focused on a particular aspect of a software system. You can't build a whole program with a DSL, but you often use multiple DSLs in a system mainly written in a general purpose language.
Domain Specific Languages (DSLs) have been around since I've been in computing, but it's hard to find much information about how to work with them. DSLs are small languages, focused on a particular aspect of a software system. You can't build a whole program with a DSL, but you often use multiple DSLs in a system mainly written in a general purpose language.
Domain Specific Languages (DSLs) have been around since I've been in computing, but it's hard to find much information about how to work with them. DSLs are small languages, focused on a particular aspect of a software system. You can't build a whole program with a DSL, but you often use multiple DSLs in a system mainly written in a general purpose language.
DSLs come in two main forms: external and internal. An external DSL is a language that's parsed independently of the host general purpose language: good examples include regular expressions and CSS. External DSLs have a strong tradition in the Unix community. Internal DSLs are a particular form of API in a host general purpose language, often referred to as a fluent interface. The way mocking libraries, such as JMock, define expectations for tests are good examples of this, as are many of the mechanisms used by Ruby on Rails. Internal DSLs also have a long tradition of usage, particularly in the Lisp community.
DSLs come in two main forms: external and internal. An external DSL is a language that's parsed independently of the host general purpose language: good examples include regular expressions and CSS. External DSLs have a strong tradition in the Unix community. Internal DSLs are a particular form of API in a host general purpose language, often referred to as a fluent interface. The way mocking libraries, such as JMock, define expectations for tests are good examples of this, as are many of the mechanisms used by Ruby on Rails. Internal DSLs also have a long tradition of usage, particularly in the Lisp community.
DSLs come in two main forms: external and internal. An external DSL is a language that's parsed independently of the host general purpose language: good examples include regular expressions and CSS. External DSLs have a strong tradition in the Unix community. Internal DSLs are a particular form of API in a host general purpose language, often referred to as a fluent interface. The way mocking libraries, such as JMock, define expectations for tests are good examples of this, as are many of the mechanisms used by Ruby on Rails. Internal DSLs also have a long tradition of usage, particularly in the Lisp community.
DSLs come in two main forms: external and internal. An external DSL is a language that's parsed independently of the host general purpose language: good examples include regular expressions and CSS. External DSLs have a strong tradition in the Unix community. Internal DSLs are a particular form of API in a host general purpose language, often referred to as a fluent interface. The way mocking libraries, such as JMock, define expectations for tests are good examples of this, as are many of the mechanisms used by Ruby on Rails. Internal DSLs also have a long tradition of usage, particularly in the Lisp community.
DSLs come in two main forms: external and internal. An external DSL is a language that's parsed independently of the host general purpose language: good examples include regular expressions and CSS. External DSLs have a strong tradition in the Unix community. Internal DSLs are a particular form of API in a host general purpose language, often referred to as a fluent interface. The way mocking libraries, such as JMock, define expectations for tests are good examples of this, as are many of the mechanisms used by Ruby on Rails. Internal DSLs also have a long tradition of usage, particularly in the Lisp community.
DSLs come in two main forms: external and internal. An external DSL is a language that's parsed independently of the host general purpose language: good examples include regular expressions and CSS. External DSLs have a strong tradition in the Unix community. Internal DSLs are a particular form of API in a host general purpose language, often referred to as a fluent interface. The way mocking libraries, such as JMock, define expectations for tests are good examples of this, as are many of the mechanisms used by Ruby on Rails. Internal DSLs also have a long tradition of usage, particularly in the Lisp community.
DSLs come in two main forms: external and internal. An external DSL is a language that's parsed independently of the host general purpose language: good examples include regular expressions and CSS. External DSLs have a strong tradition in the Unix community. Internal DSLs are a particular form of API in a host general purpose language, often referred to as a fluent interface. The way mocking libraries, such as JMock, define expectations for tests are good examples of this, as are many of the mechanisms used by Ruby on Rails. Internal DSLs also have a long tradition of usage, particularly in the Lisp community.
DSLs come in two main forms: external and internal. An external DSL is a language that's parsed independently of the host general purpose language: good examples include regular expressions and CSS. External DSLs have a strong tradition in the Unix community. Internal DSLs are a particular form of API in a host general purpose language, often referred to as a fluent interface. The way mocking libraries, such as JMock, define expectations for tests are good examples of this, as are many of the mechanisms used by Ruby on Rails. Internal DSLs also have a long tradition of usage, particularly in the Lisp community.
Typically, a domain-specific language is created when a development team has to write similar code for several products. For example, a company that specializes in baggage handling systems might define a baggage track DSL from which they can generate some of the code for each installation. The benefits of the DSL are that it can be understood by their customers, that the code generated from it is reliable, and that the system can be rapidly updated if the customers' requirements change.
Typically, a domain-specific language is created when a development team has to write similar code for several products. For example, a company that specializes in baggage handling systems might define a baggage track DSL from which they can generate some of the code for each installation. The benefits of the DSL are that it can be understood by their customers, that the code generated from it is reliable, and that the system can be rapidly updated if the customers' requirements change.
Typically, a domain-specific language is created when a development team has to write similar code for several products. For example, a company that specializes in baggage handling systems might define a baggage track DSL from which they can generate some of the code for each installation. The benefits of the DSL are that it can be understood by their customers, that the code generated from it is reliable, and that the system can be rapidly updated if the customers' requirements change.

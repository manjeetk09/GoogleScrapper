algorithms for supervised learning;https://www.mathworks.com/discovery/supervised-learning.html;Neural networks.;Artificial neural network;neural_networks;0.6363636363636364;0.2;0.42857142857142855;1.264935064935065;0.0;1;Mon Jun 26 00:43:53 IST 2017
algorithms for supervised learning;https://www.mathworks.com/discovery/supervised-learning.html;Decision trees.;Decision tree;decision_tree;0.6363636363636364;0.2;0.42857142857142855;1.264935064935065;0.0;1;Mon Jun 26 00:43:53 IST 2017
algorithms for supervised learning;https://www.mathworks.com/discovery/supervised-learning.html;Supervised learning is a type of machine learning algorithm that uses a known dataset to make predictions.;Outline of machine learning;machine_learning_algorithms;0.9393939393939394;0.05263157894736842;1.0;1.9920255183413078;1.0;0;Mon Jun 26 00:43:53 IST 2017
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;Dalila says  August 14, 2015 at 1 35 pm Very good summary  Thank  One simple point  The reason for taking the log  in Logistic Regression is to make the equation linear, I e , easy to solve  Sunil Ray says  August 21, 2015 at 5 21 am Thanks Dalila    Borun Chowdhury says  April 21, 2016 at 8 48 am That s not the reason for taking the log  The underlying assumption in logistic regression is that the probability is governed by a step function whose argument is linear in the attributes  First of all the assumption of linearity or otherwise introduces bias  However, logistic regression being a parametric model some bias is inevitable  The reason to choose a linear relationship is not because its easy to solve but because a higher order polynomial introduces higher bias and one would not like to do so without good reason  Now coming to the choice of log, it is just a convention  Basically, once we have decided to go with a linear model, in the case of one attribute we model the probability by p  fsuch that p 0 and p 0  It so happens that this is satisfied by p  exp    which can be re_written as log     a x  b While I am at it, it may be useful to talk about another point  One should ask is why we don t use least square method  The reason is that a yes no choice is a Bernoulli random variable and thus we estimate the probability according to maximum likelihood wrt Bernoulli process  For linear regression the assumption is that the residuals around the  true  function are distributed according to a normal distribution and the maximum likelihood estimate for a normal distribution amounts to the least square method  So deep down linear regression and logistic regression both use maximum likelihood estimates  Its just that they are max likelihoods according to different distributions .;Normal distribution;normal_distribution;0.8181818181818182;0.0018867924528301887;1.0;1.8200686106346484;1.0;0;Mon Jun 26 00:43:53 IST 2017
algorithms for supervised learning;http://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html;Machine learning algorithms can be divided into 3 broad categories   supervised learning, unsupervised learning, and reinforcement learning.;Unsupervised learning;unsupervised_learning;0.6969696969690908;0.09090909090909091;1.0;1.7878787878781819;0.7071067811865475;0;Mon Jun 26 00:43:53 IST 2017
algorithms for supervised learning;http://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html;Machine learning algorithms can be divided into 3 broad categories   supervised learning, unsupervised learning, and reinforcement learning.;Reinforcement learning;reinforcement_learning;0.6969696969690908;0.06060606060606061;1.0;1.7575757575751514;0.7071067811865475;0;Mon Jun 26 00:43:53 IST 2017
algorithms for supervised learning;http://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html; Reinforcement learning falls between these 2 extremes   there is some form of feedback available for each predictive step or action, but no precise label or error message.;Error message;error_messages;0.6363636363636364;0.030303030303030304;1.0;1.6666666666666665;0.0;0;Mon Jun 26 00:43:53 IST 2017
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;Dalila says  August 14, 2015 at 1 35 pm Very good summary  Thank  One simple point  The reason for taking the log  in Logistic Regression is to make the equation linear, I e , easy to solve  Sunil Ray says  August 21, 2015 at 5 21 am Thanks Dalila    Borun Chowdhury says  April 21, 2016 at 8 48 am That s not the reason for taking the log  The underlying assumption in logistic regression is that the probability is governed by a step function whose argument is linear in the attributes  First of all the assumption of linearity or otherwise introduces bias  However, logistic regression being a parametric model some bias is inevitable  The reason to choose a linear relationship is not because its easy to solve but because a higher order polynomial introduces higher bias and one would not like to do so without good reason  Now coming to the choice of log, it is just a convention  Basically, once we have decided to go with a linear model, in the case of one attribute we model the probability by p  fsuch that p 0 and p 0  It so happens that this is satisfied by p  exp    which can be re_written as log     a x  b While I am at it, it may be useful to talk about another point  One should ask is why we don t use least square method  The reason is that a yes no choice is a Bernoulli random variable and thus we estimate the probability according to maximum likelihood wrt Bernoulli process  For linear regression the assumption is that the residuals around the  true  function are distributed according to a normal distribution and the maximum likelihood estimate for a normal distribution amounts to the least square method  So deep down linear regression and logistic regression both use maximum likelihood estimates  Its just that they are max likelihoods according to different distributions .;Step function;step_function;0.6363636363636364;0.0018867924528301887;1.0;1.6382504288164665;1.0;0;Mon Jun 26 00:43:53 IST 2017
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;Dung Dinh says  June 17, 2016 at 10 24 am The amazing article  I m new in data analysis  It s very useful and easy to understand  Thanks,.;Data analysis;data_analysis;0.6363636363636364;0.0018867924528301887;1.0;1.6382504288164665;0.0;0;Mon Jun 26 00:43:53 IST 2017
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;sanjiv says  September 8, 2016 at 4 29 am Great article  It would have become even better if you had some test data with each code snippet  Add metrics and hyper parameter tunning for each of these models.;Text corpus;text_data;0.6363636363636364;0.0018867924528301887;1.0;1.6382504288164665;0.7071067811865475;0;Mon Jun 26 00:43:53 IST 2017
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;Dalila says  August 14, 2015 at 1 35 pm Very good summary  Thank  One simple point  The reason for taking the log  in Logistic Regression is to make the equation linear, I e , easy to solve  Sunil Ray says  August 21, 2015 at 5 21 am Thanks Dalila    Borun Chowdhury says  April 21, 2016 at 8 48 am That s not the reason for taking the log  The underlying assumption in logistic regression is that the probability is governed by a step function whose argument is linear in the attributes  First of all the assumption of linearity or otherwise introduces bias  However, logistic regression being a parametric model some bias is inevitable  The reason to choose a linear relationship is not because its easy to solve but because a higher order polynomial introduces higher bias and one would not like to do so without good reason  Now coming to the choice of log, it is just a convention  Basically, once we have decided to go with a linear model, in the case of one attribute we model the probability by p  fsuch that p 0 and p 0  It so happens that this is satisfied by p  exp    which can be re_written as log     a x  b While I am at it, it may be useful to talk about another point  One should ask is why we don t use least square method  The reason is that a yes no choice is a Bernoulli random variable and thus we estimate the probability according to maximum likelihood wrt Bernoulli process  For linear regression the assumption is that the residuals around the  true  function are distributed according to a normal distribution and the maximum likelihood estimate for a normal distribution amounts to the least square method  So deep down linear regression and logistic regression both use maximum likelihood estimates  Its just that they are max likelihoods according to different distributions .;Linear A;linear_a;0.5757575757563637;0.0;1.0;1.5757575757563638;1.0;0;Mon Jun 26 00:43:53 IST 2017
genetic algorithm for supervised learning;http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/; Natural Language Processing .;Natural language processing;natural_language_processing;1.0;0.029411764705882353;0.42857142857142855;1.4579831932773109;0.0;0;Mon Jun 26 00:43:53 IST 2017
genetic algorithm for supervised learning;https://stackoverflow.com/questions/20752232/is-a-genetic-algorithm-a-form-of-unsupervised-learning;Genetic Algorithms can be used for both supervised and unsupervised learning, e.;Genetic algorithm;genetic_algorithms;0.6363636363636364;0.3333333333333333;0.14285714285714285;1.1125541125541125;1.0;0;Mon Jun 26 00:43:53 IST 2017
genetic algorithm for supervised learning;http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/;Develop Your First Neural Network in Python With Keras Step_By_Step May 24, 2016.;Artificial neural network;neural_network;0.6363636363636364;0.029411764705882353;0.42857142857142855;1.0943468296409473;0.0;0;Mon Jun 26 00:43:53 IST 2017
genetic algorithm for supervised learning;http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/;I also did not cover algorithms from specialty subfields of machine learning, such as.;Machine learning;machine_learning;0.6363636363636364;0.029411764705882353;0.42857142857142855;1.0943468296409473;0.7071067811865475;0;Mon Jun 26 00:43:53 IST 2017
genetic algorithm for supervised learning;http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/; Computer Vision .;Computer vision;computer_vision;0.6363636363636364;0.029411764705882353;0.42857142857142855;1.0943468296409473;0.0;0;Mon Jun 26 00:43:53 IST 2017
genetic algorithm for supervised learning;http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/; Graphical Models.;Graphical model;graphical_model;0.6363636363636364;0.029411764705882353;0.42857142857142855;1.0943468296409473;0.0;0;Mon Jun 26 00:43:53 IST 2017
genetic algorithm for supervised learning;http://link.springer.com/chapter/10.1007/978-1-4615-2740-4_3; The method of abstracting the genetic algorithm to the problem level, described here for the supervised inductive learning, can be also extended to other domains and tasks, since it provides a framework for combining recently popular genetic algorithm methods with traditional problem_solving methodologies.;Genetic algorithm;genetic_algorithm;0.6363636363636364;0.02564102564102564;0.42857142857142855;1.0905760905760906;0.7071067811865475;0;Mon Jun 26 00:43:53 IST 2017
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;ramesh says  October 23, 2016 at 12 35 pm Hi Friends, i m new person to these machine learning algorithms  i have some questions   1  we have so many ML algorithms  but how can we choose the algorithms which one is suitable for my data set  2  How does these algorithms works   3  why only these particular algorithms   why not others  .;Algorithm;algorithms;0.5636363636363636;0.0037735849056603774;0.42857142857142855;0.9959813771134525;0.7071067811865475;0;Mon Jun 26 00:43:53 IST 2017
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;Dalila says  August 14, 2015 at 1 35 pm Very good summary  Thank  One simple point  The reason for taking the log  in Logistic Regression is to make the equation linear, I e , easy to solve  Sunil Ray says  August 21, 2015 at 5 21 am Thanks Dalila    Borun Chowdhury says  April 21, 2016 at 8 48 am That s not the reason for taking the log  The underlying assumption in logistic regression is that the probability is governed by a step function whose argument is linear in the attributes  First of all the assumption of linearity or otherwise introduces bias  However, logistic regression being a parametric model some bias is inevitable  The reason to choose a linear relationship is not because its easy to solve but because a higher order polynomial introduces higher bias and one would not like to do so without good reason  Now coming to the choice of log, it is just a convention  Basically, once we have decided to go with a linear model, in the case of one attribute we model the probability by p  fsuch that p 0 and p 0  It so happens that this is satisfied by p  exp    which can be re_written as log     a x  b While I am at it, it may be useful to talk about another point  One should ask is why we don t use least square method  The reason is that a yes no choice is a Bernoulli random variable and thus we estimate the probability according to maximum likelihood wrt Bernoulli process  For linear regression the assumption is that the residuals around the  true  function are distributed according to a normal distribution and the maximum likelihood estimate for a normal distribution amounts to the least square method  So deep down linear regression and logistic regression both use maximum likelihood estimates  Its just that they are max likelihoods according to different distributions .;Conceptual model;model;0.5151515151527273;0.0037735849056603774;0.23809523809523808;0.7570203381536258;1.0;0;Mon Jun 26 00:43:53 IST 2017
quantum algorithms for supervised and unsupervised machine learning;https://en.wikipedia.org/wiki/Quantum_machine_learning; Quantum machine learning algorithms can use the advantages of quantum computation in order to improve classical methods of machine learning, for example by developing efficient implementations of expensive classical algorithms on a quantum computer.;Quantum computing;quantum_computer;0.6363636363636364;0.038461538461538464;0.0;0.6748251748251748;0.7071067811865475;0;Mon Jun 26 00:43:53 IST 2017

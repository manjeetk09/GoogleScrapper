algorithms for supervised learning;https://www.mathworks.com/discovery/supervised-learning.html;Support vector machines .;support_vector_machines;1.0;0.2;0.28888888888888886;1.488888888888889;0.0;1;Wed Jun 14 11:22:59 IST 2017;support_vector_machines;support_vector_machine;supervised_learning
algorithms for supervised learning;https://www.mathworks.com/discovery/supervised-learning.html;Neural networks.;neural_networks;0.6363636363636364;0.2;0.4666666666666667;1.3030303030303032;0.0;1;Wed Jun 14 11:22:59 IST 2017
algorithms for supervised learning;https://www.mathworks.com/discovery/supervised-learning.html;Decision trees.;decision_tree;0.6363636363636364;0.2;0.4666666666666667;1.3030303030303032;0.0;1;Wed Jun 14 11:22:59 IST 2017
algorithms for supervised learning;http://scikit-learn.org/stable/supervised_learning.html;1 6  Nearest Neighbors 1 6 1  Unsupervised Nearest Neighbors 1 6 1 1  Finding the Nearest Neighbors 1 6 1 2  KDTree and BallTree Classes 1 6 2  Nearest Neighbors Classification 1 6 3  Nearest Neighbors Regression 1 6 4  Nearest Neighbor Algorithms 1 6 4 1  Brute Force 1 6 4 2  K_D Tree 1 6 4 3  Ball Tree 1 6 4 4  Choice of Nearest Neighbors Algorithm 1 6 4 5  Effect of leaf_size 1 6 5  Nearest Centroid Classifier 1 6 5 1  Nearest Shrunken Centroid 1 6 6  Approximate Nearest Neighbors 1 6 6 1  Locality Sensitive Hashing Forest 1 6 6 2  Mathematical description of Locality Sensitive Hashing.;locality-sensitive_hashing;1.0;0.032679738562091505;1.0;2.0326797385620914;0.0;0;Wed Jun 14 11:22:59 IST 2017
algorithms for supervised learning;https://www.mathworks.com/discovery/supervised-learning.html;Supervised learning is a type of machine learning algorithm that uses a known dataset to make predictions.;machine_learning_algorithms;0.9393939393939394;0.05263157894736842;1.0;1.9920255183413078;0.0;0;Wed Jun 14 11:22:59 IST 2017
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;Dalila says  August 14, 2015 at 1 35 pm Very good summary  Thank  One simple point  The reason for taking the log  in Logistic Regression is to make the equation linear, I e , easy to solve  Sunil Ray says  August 21, 2015 at 5 21 am Thanks Dalila    Borun Chowdhury says  April 21, 2016 at 8 48 am That s not the reason for taking the log  The underlying assumption in logistic regression is that the probability is governed by a step function whose argument is linear in the attributes  First of all the assumption of linearity or otherwise introduces bias  However, logistic regression being a parametric model some bias is inevitable  The reason to choose a linear relationship is not because its easy to solve but because a higher order polynomial introduces higher bias and one would not like to do so without good reason  Now coming to the choice of log, it is just a convention  Basically, once we have decided to go with a linear model, in the case of one attribute we model the probability by p  fsuch that p 0 and p 0  It so happens that this is satisfied by p  exp    which can be re_written as log     a x  b While I am at it, it may be useful to talk about another point  One should ask is why we don t use least square method  The reason is that a yes no choice is a Bernoulli random variable and thus we estimate the probability according to maximum likelihood wrt Bernoulli process  For linear regression the assumption is that the residuals around the  true  function are distributed according to a normal distribution and the maximum likelihood estimate for a normal distribution amounts to the least square method  So deep down linear regression and logistic regression both use maximum likelihood estimates  Its just that they are max likelihoods according to different distributions .;normal_distribution;0.8181818181818182;0.0018867924528301887;1.0;1.8200686106346484;0.0;0;Wed Jun 14 11:22:59 IST 2017
algorithms for supervised learning;https://en.wikipedia.org/wiki/Supervised_learning;The most widely used learning algorithms are Support Vector Machines, linear regression, logistic regression, naive Bayes, linear discriminant analysis, decision trees, k_nearest neighbor algorithm, and Neural Networks .;naive_bayes;0.6363636363636364;0.09090909090909091;1.0;1.7272727272727273;0.0;0;Wed Jun 14 11:22:59 IST 2017;naive_bayes;naive_baye;bayesian_network;supervised_learning
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;Dalila says  August 14, 2015 at 1 35 pm Very good summary  Thank  One simple point  The reason for taking the log  in Logistic Regression is to make the equation linear, I e , easy to solve  Sunil Ray says  August 21, 2015 at 5 21 am Thanks Dalila    Borun Chowdhury says  April 21, 2016 at 8 48 am That s not the reason for taking the log  The underlying assumption in logistic regression is that the probability is governed by a step function whose argument is linear in the attributes  First of all the assumption of linearity or otherwise introduces bias  However, logistic regression being a parametric model some bias is inevitable  The reason to choose a linear relationship is not because its easy to solve but because a higher order polynomial introduces higher bias and one would not like to do so without good reason  Now coming to the choice of log, it is just a convention  Basically, once we have decided to go with a linear model, in the case of one attribute we model the probability by p  fsuch that p 0 and p 0  It so happens that this is satisfied by p  exp    which can be re_written as log     a x  b While I am at it, it may be useful to talk about another point  One should ask is why we don t use least square method  The reason is that a yes no choice is a Bernoulli random variable and thus we estimate the probability according to maximum likelihood wrt Bernoulli process  For linear regression the assumption is that the residuals around the  true  function are distributed according to a normal distribution and the maximum likelihood estimate for a normal distribution amounts to the least square method  So deep down linear regression and logistic regression both use maximum likelihood estimates  Its just that they are max likelihoods according to different distributions .;step_function;0.6363636363636364;0.0018867924528301887;1.0;1.6382504288164665;0.0;0;Wed Jun 14 11:22:59 IST 2017
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;Dung Dinh says  June 17, 2016 at 10 24 am The amazing article  I m new in data analysis  It s very useful and easy to understand  Thanks,.;data_analysis;0.6363636363636364;0.0018867924528301887;1.0;1.6382504288164665;0.0;0;Wed Jun 14 11:22:59 IST 2017
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;sanjiv says  September 8, 2016 at 4 29 am Great article  It would have become even better if you had some test data with each code snippet  Add metrics and hyper parameter tunning for each of these models.;text_data;0.6363636363636364;0.0018867924528301887;1.0;1.6382504288164665;0.0;0;Wed Jun 14 11:22:59 IST 2017
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;Dalila says  August 14, 2015 at 1 35 pm Very good summary  Thank  One simple point  The reason for taking the log  in Logistic Regression is to make the equation linear, I e , easy to solve  Sunil Ray says  August 21, 2015 at 5 21 am Thanks Dalila    Borun Chowdhury says  April 21, 2016 at 8 48 am That s not the reason for taking the log  The underlying assumption in logistic regression is that the probability is governed by a step function whose argument is linear in the attributes  First of all the assumption of linearity or otherwise introduces bias  However, logistic regression being a parametric model some bias is inevitable  The reason to choose a linear relationship is not because its easy to solve but because a higher order polynomial introduces higher bias and one would not like to do so without good reason  Now coming to the choice of log, it is just a convention  Basically, once we have decided to go with a linear model, in the case of one attribute we model the probability by p  fsuch that p 0 and p 0  It so happens that this is satisfied by p  exp    which can be re_written as log     a x  b While I am at it, it may be useful to talk about another point  One should ask is why we don t use least square method  The reason is that a yes no choice is a Bernoulli random variable and thus we estimate the probability according to maximum likelihood wrt Bernoulli process  For linear regression the assumption is that the residuals around the  true  function are distributed according to a normal distribution and the maximum likelihood estimate for a normal distribution amounts to the least square method  So deep down linear regression and logistic regression both use maximum likelihood estimates  Its just that they are max likelihoods according to different distributions .;linear_a;0.5757575757563637;0.0;1.0;1.5757575757563638;0.0;0;Wed Jun 14 11:22:59 IST 2017
algorithms for supervised learning;https://en.wikipedia.org/wiki/Supervised_learning;The most widely used learning algorithms are Support Vector Machines, linear regression, logistic regression, naive Bayes, linear discriminant analysis, decision trees, k_nearest neighbor algorithm, and Neural Networks .;linear_discriminant_analysis;0.9393939393939394;0.09090909090909091;0.4666666666666667;1.496969696969697;0.0;0;Wed Jun 14 11:22:59 IST 2017;linear_discriminant_analysis;pattern_recognition;supervised_learning
genetic algorithm for supervised learning;https://stackoverflow.com/questions/20752232/is-a-genetic-algorithm-a-form-of-unsupervised-learning;Genetic Algorithms can be used for both supervised and unsupervised learning, e.;genetic_algorithms;0.6363636363636364;0.3333333333333333;0.3333333333333333;1.303030303030303;0.0;0;Wed Jun 14 11:22:59 IST 2017
genetic algorithm for supervised learning;https://www.quora.com/Is-genetic-algorithm-considered-a-supervised-or-non-supervised-algorithm;Supervised and unsupervised are related to learning, which may use any search or optimization tool like genetic algorithm, gradient based algorithm etc.;genetic_algorithm;0.7272727272727273;0.125;0.3333333333333333;1.1856060606060606;0.0;0;Wed Jun 14 11:22:59 IST 2017
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;Benjamin says  December 5, 2015 at 7 00 pm This is a great resource overall and surely the product of a lot of work  Just a note as I go through this, your comment on Logistic Regression not actually being regression is in fact wrong  It maps outputs to a continuous variable bound between 0 and 1 that we regard as probability  it makes classification easy but that is still an extra step that requires the choice of a threshold which is not the main aim of Logistic Regression  As a matter of fact it falls under the umbrella of Generalized Libear Models as the glm R package hints it in your code example  I thought this was interesting to note so as not to forget that logistic regression output is richer than 0 or 1  Thanks for the great article overall .;logistic_regression;0.6969696969690908;0.0037735849056603774;0.4666666666666667;1.167409948541418;0.0;0;Wed Jun 14 11:22:59 IST 2017;logistic_regression;linear_classifier;supervised_learning
algorithms for supervised learning;https://en.wikipedia.org/wiki/Supervised_learning;The most widely used learning algorithms are Support Vector Machines, linear regression, logistic regression, naive Bayes, linear discriminant analysis, decision trees, k_nearest neighbor algorithm, and Neural Networks .;linear_regression;0.7272727272727273;0.09090909090909091;0.28888888888888886;1.107070707070707;0.0;0;Wed Jun 14 11:22:59 IST 2017;linear_regression;linear_classifier;supervised_learning
genetic algorithm for supervised learning;https://stackoverflow.com/questions/20752232/is-a-genetic-algorithm-a-form-of-unsupervised-learning;Genetic Algorithms can be used for both supervised and unsupervised learning, e.;unsupervised_learning;0.6363636363636364;0.3333333333333333;0.13333333333333333;1.103030303030303;0.0;0;Wed Jun 14 11:22:59 IST 2017
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;ramesh says  October 23, 2016 at 12 35 pm Hi Friends, i m new person to these machine learning algorithms  i have some questions   1  we have so many ML algorithms  but how can we choose the algorithms which one is suitable for my data set  2  How does these algorithms works   3  why only these particular algorithms   why not others  .;algorithms;0.5636363636363636;0.0037735849056603774;0.4666666666666667;1.0340766152086907;0.0;0;Wed Jun 14 11:22:59 IST 2017
quantum algorithms for supervised and unsupervised machine learning;https://en.wikipedia.org/wiki/Quantum_machine_learning;Quantum machine learning is an emerging interdisciplinary research area at the intersection of quantum physics and machine learning.;machine_learning;0.8181818181818182;0.11538461538461539;0.06666666666666667;1.0002331002331004;0.0;0;Wed Jun 14 11:22:59 IST 2017
quantum algorithms for supervised and unsupervised machine learning;http://peterwittek.com/book.html; What Quantum Computing Means to Data Mining explains the most relevant concepts of machine learning, quantum mechanics, and quantum information theory, and contrasts classical learning algorithms to their quantum counterparts.;quantum_mechanics;0.7272727272727273;0.06666666666666667;0.2;0.9939393939393939;0.0;0;Wed Jun 14 11:22:59 IST 2017
quantum algorithms for supervised and unsupervised machine learning;http://peterwittek.com/book.html; Rebentrost,  Quantum algorithms for supervised and unsupervised machine learning,  arXiv.;quantum_algorithms;0.6363636363636364;0.06666666666666667;0.2;0.9030303030303031;0.0;0;Wed Jun 14 11:22:59 IST 2017
quantum algorithms for supervised and unsupervised machine learning;https://en.wikipedia.org/wiki/Quantum_machine_learning; Quantum machine learning algorithms can use the advantages of quantum computation in order to improve classical methods of machine learning, for example by developing efficient implementations of expensive classical algorithms on a quantum computer.;quantum_computation;0.6363636363636364;0.038461538461538464;0.2;0.8748251748251747;0.0;0;Wed Jun 14 11:22:59 IST 2017
quantum algorithms for supervised and unsupervised machine learning;https://en.wikipedia.org/wiki/Quantum_machine_learning; Quantum machine learning algorithms can use the advantages of quantum computation in order to improve classical methods of machine learning, for example by developing efficient implementations of expensive classical algorithms on a quantum computer.;quantum_computer;0.6363636363636364;0.038461538461538464;0.2;0.8748251748251747;0.0;0;Wed Jun 14 11:22:59 IST 2017
algorithms for supervised learning;https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/;Dalila says  August 14, 2015 at 1 35 pm Very good summary  Thank  One simple point  The reason for taking the log  in Logistic Regression is to make the equation linear, I e , easy to solve  Sunil Ray says  August 21, 2015 at 5 21 am Thanks Dalila    Borun Chowdhury says  April 21, 2016 at 8 48 am That s not the reason for taking the log  The underlying assumption in logistic regression is that the probability is governed by a step function whose argument is linear in the attributes  First of all the assumption of linearity or otherwise introduces bias  However, logistic regression being a parametric model some bias is inevitable  The reason to choose a linear relationship is not because its easy to solve but because a higher order polynomial introduces higher bias and one would not like to do so without good reason  Now coming to the choice of log, it is just a convention  Basically, once we have decided to go with a linear model, in the case of one attribute we model the probability by p  fsuch that p 0 and p 0  It so happens that this is satisfied by p  exp    which can be re_written as log     a x  b While I am at it, it may be useful to talk about another point  One should ask is why we don t use least square method  The reason is that a yes no choice is a Bernoulli random variable and thus we estimate the probability according to maximum likelihood wrt Bernoulli process  For linear regression the assumption is that the residuals around the  true  function are distributed according to a normal distribution and the maximum likelihood estimate for a normal distribution amounts to the least square method  So deep down linear regression and logistic regression both use maximum likelihood estimates  Its just that they are max likelihoods according to different distributions .;model;0.5151515151527273;0.0037735849056603774;0.28888888888888886;0.8078139889472765;0.0;0;Wed Jun 14 11:22:59 IST 2017
supervised learning algorithms for sentiment analysis;http://www.sciencedirect.com/science/article/pii/S2090447914000550;Sentiment Analysis is an ongoing field of research in text mining field.;sentiment_analysis;0.6363636363636364;0.04878048780487805;0.06666666666666667;0.7518107908351811;0.0;0;Wed Jun 14 11:22:59 IST 2017;sentiment_analysis;text_mining;information_extraction;supervised_learning
supervised learning algorithms for sentiment analysis;http://www.sciencedirect.com/science/article/pii/S2090447914000550; The related fields to SA that attracted researchers recently are discussed.;related_fields;0.6363636363636364;0.04878048780487805;0.06666666666666667;0.7518107908351811;0.0;0;Wed Jun 14 11:22:59 IST 2017
supervised learning algorithms for sentiment analysis;http://www.sciencedirect.com/science/article/pii/S2090447914000550; The main contributions of this paper include the sophisticated categorizations of a large number of recent articles and the illustration of the recent trend of research in the sentiment analysis and its related areas.;large_numbers;0.6363636363636364;0.024390243902439025;0.06666666666666667;0.727420546932742;0.0;0;Wed Jun 14 11:22:59 IST 2017

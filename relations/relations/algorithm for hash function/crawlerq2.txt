By Bob Jenkins, September 01, 1997.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
By John Boyer, January 01, 1998.
.
.
.
.
.
.
.
.
More recently, Bob Jenkins presented a hashing function that performs a complex mixing operation using 12 bytes at a time from the input key.
 By design, the bytes of the key have some affect on all regions of the hash value.
 Thus, the hash function suffers little or no information loss when the hash value is truncated to the table size.
 As Table 1 shows, the efficiency of Jenkins  hash function was far greater than the original HashPJW, and even slightly better than HashJBand the new HashPJW.
 The run time using HashJBis equivalent to HashJenkinsbecause the former uses slightly less CPU time to compute hash values.
DDJ.
.
.
.
.
.
.
.
.
The Jenkins hash functions are a collection of hash functions for multi_byte keys designed by Bob Jenkins.
 The first one was formally published in 1997.
       .
.
.
       .
.
.
       .
.
.
I offer you a new hash function for hash table lookup that is faster and more thorough than the one you are using now.
 I also give you a way to verify that it is more thorough.
I have three complaints against it.
 First, it s specific about how to reduce the size if you don t use all the bits, it s not just a mask.
 Increasing the result size by one bit gives you a completely different hash.
 If you use a hash table that grows by increasing the result size by one bit, one old bucket maps across the entire new table, not to just two new buckets.
 If your algorithm has a sliding pointer for which buckets have been split, that just won t work with FNV.
 Second, it s linear.
 That means that widely separated things can cancel each other out at least as easily as nearby things.
 Third, since multiplication only affects higher bits, the lowest 7 bits of the state are never affected by the 8th bit of all the input bytes.
 Algorithm Alley  explores the design and implementation of algorithms.
 Every month I ll present useful algorithms that you can implement today.
 The algorithms will cover a variety of areas__computation, graphics, databases, networking, artificial intelligence, and more__and be relevant to many more applications.
My first column is about Bloom filters, a method of hashing that greatly reduces memory requirements at the expense of false  hits.
  They are useful in a variety of applications, particularly those in which no calculation is required if the search is unsuccessful.
 For example, you might want to check someone s credit rating or passport number, but do nothing else if the record doesn t exist.
 While Bloom filters will occasionally report that a record exists when it doesn t, they ll never erroneously report that a record doesn t exist when it does.
Open any book on algorithms and you will find a chapter on searching.
 In that chapter, there will be a discussion on hashing.
 But after a short introduction to hashing and hash functions, you ll find that the bulk of the material is about collision resolution  see, for instance, The Art of Computer Programming, Vol.
3.
 Sorting and Searching, by D.
E.
 Knuth, Addison_Wesley, 1997 .
The BDZ algorithm was designed by Fabiano C.
 Botelho, Djamal Belazzougui, Rasmus Pagh and Nivio Ziviani.
 It is a simple, efficient, near_optimal space and practical algorithm to generate a family of PHFs and MPHFs.
 It is also referred to as BPZ algorithm because the work presented by Botelho, Pagh and Ziviani in .
 In the Botelho s PhD.
 dissertation  it is also referred to as RAM algorithm because it is more suitable for key sets that can be handled in internal memory.
Nivio Ziviani.
